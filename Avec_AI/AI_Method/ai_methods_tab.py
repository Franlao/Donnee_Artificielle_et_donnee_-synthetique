import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import io
import base64
import os
import json
from PIL import Image
import time
import tempfile
import pickle
from typing import Tuple, Dict, List, Union, Optional, Any

# Importer les modules d√©compos√©s
from .data_processor import DataProcessor, DatasetMetadata
from .llm_generator import MistralGenerator, MISTRAL_AVAILABLE
from .ui_components import render_llm_tab, visualize_categorical_comparison, visualize_numeric_comparison
from .load_csv_safe import load_csv_safely
from .missing_values_handler import missing_values_module
# Importer le module des mod√®les
try:
    from .models import (
        train_gan_model, 
        train_vae_model, 
        save_model, 
        load_model, 
        GAN_AVAILABLE, 
        VAE_AVAILABLE, 
        CUDA_AVAILABLE
    )
except ImportError:
    # D√©finir des valeurs par d√©faut si le module n'est pas disponible
    GAN_AVAILABLE = False
    VAE_AVAILABLE = False
    CUDA_AVAILABLE = False

# Essayer d'importer PyTorch
try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader, TensorDataset
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("PyTorch n'est pas install√©. Pour l'installer: pip install torch")

# M√©thodes statistiques simples
from sklearn.mixture import GaussianMixture
from sklearn.decomposition import PCA

def generate_with_statistical_methods(preprocessed_data, metadata, method_type, n_components, n_samples):
    """
    G√©n√®re des donn√©es synth√©tiques en utilisant des m√©thodes statistiques simples.
    
    Args:
        preprocessed_data: Donn√©es pr√©trait√©es
        metadata: M√©tadonn√©es
        method_type: Type de m√©thode ('gmm' ou 'pca')
        n_components: Nombre de composantes
        n_samples: Nombre d'√©chantillons √† g√©n√©rer
        
    Returns:
        Donn√©es synth√©tiques g√©n√©r√©es
    """
    if method_type == 'gmm':
        # Utiliser un m√©lange de gaussiennes
        gmm = GaussianMixture(n_components=n_components, covariance_type='full', random_state=42)
        gmm.fit(preprocessed_data)
        
        # G√©n√©rer des √©chantillons
        samples, _ = gmm.sample(n_samples=n_samples)
        return samples
        
    elif method_type == 'pca':
        # Utiliser PCA pour la r√©duction de dimension + reconstruction
        pca = PCA(n_components=n_components)
        reduced = pca.fit_transform(preprocessed_data)
        
        # G√©n√©rer des √©chantillons en √©chantillonnant l'espace r√©duit
        random_reduced = np.random.normal(
            loc=np.mean(reduced, axis=0),
            scale=np.std(reduced, axis=0),
            size=(n_samples, n_components)
        )
        
        # Reconstruire les donn√©es
        reconstructed = pca.inverse_transform(random_reduced)
        return reconstructed
    
    else:
        raise ValueError(f"M√©thode statistique non reconnue: {method_type}")

# Nouvelle fonction pour afficher l'interface de gestion des valeurs manquantes
def show_missing_values_interface():
    """Affiche une interface d√©di√©e √† la gestion des valeurs manquantes"""
    if not hasattr(st.session_state, 'original_data'):
        st.error("Aucune donn√©e √† traiter. Veuillez d'abord charger un fichier.")
        return
    
    st.title("Gestion des Valeurs Manquantes")
    
    # R√©cup√©rer les donn√©es originales
    data = st.session_state.original_data.copy()
    
    # Nettoyer les donn√©es pour l'affichage
    clean_data = clean_dataframe_for_display(data)
    
    # Afficher un aper√ßu des donn√©es originales
    st.subheader("Aper√ßu des Donn√©es")
    st.dataframe(clean_data.head())
    
    # Analyser les valeurs manquantes
    missing_total = data.isnull().sum().sum()
    missing_by_col = data.isnull().sum()
    missing_cols = missing_by_col[missing_by_col > 0].index.tolist()
    
    # Afficher les statistiques des valeurs manquantes
    st.subheader("Analyse des Valeurs Manquantes")
    st.write(f"Nombre total de valeurs manquantes: **{missing_total}**")
    
    # Cr√©er un dataframe pour afficher les colonnes avec valeurs manquantes
    missing_df = pd.DataFrame({
        'Colonne': missing_cols,
        'Valeurs manquantes': [missing_by_col[col] for col in missing_cols],
        'Pourcentage': [f"{missing_by_col[col] / len(data) * 100:.2f}%" for col in missing_cols]
    })
    
    st.write("Valeurs manquantes par colonne:")
    st.dataframe(missing_df)
    
    # Visualiser les valeurs manquantes
    st.subheader("Visualisation des Valeurs Manquantes")
    
    # Heatmap
    fig, ax = plt.subplots(figsize=(12, 6))
    sns.heatmap(data[missing_cols].isnull(), cmap='viridis', yticklabels=False, cbar=False, ax=ax)
    ax.set_title('Heatmap des valeurs manquantes')
    st.pyplot(fig)
    
    # Graphique √† barres
    fig, ax = plt.subplots(figsize=(10, 6))
    missing_by_col[missing_cols].sort_values(ascending=False).plot(kind='bar', ax=ax)
    ax.set_title('Nombre de valeurs manquantes par colonne')
    ax.set_ylabel('Nombre de valeurs manquantes')
    plt.tight_layout()
    st.pyplot(fig)
    
    # S√©lection des m√©thodes de traitement
    st.subheader("Traitement des Valeurs Manquantes")
    
    # Cr√©er des onglets pour les diff√©rentes m√©thodes
    treatment_tabs = st.tabs([
        "Suppression", 
        "Imputation Simple", 
        "Imputation Avanc√©e",
        "R√©sultats"
    ])
    
    # Variable pour stocker les donn√©es trait√©es
    treated_data = None
    
    # Onglet 1: Suppression
    with treatment_tabs[0]:
        st.write("### Suppression des lignes ou colonnes avec valeurs manquantes")
        
        removal_method = st.radio(
            "M√©thode de suppression:",
            ["Supprimer les lignes", "Supprimer les colonnes"]
        )
        
        if removal_method == "Supprimer les lignes":
            threshold = st.slider(
                "Seuil de suppression (% maximum de valeurs manquantes par ligne)",
                min_value=0,
                max_value=100,
                value=50,
                step=5,
                help="Les lignes avec un pourcentage de valeurs manquantes sup√©rieur √† ce seuil seront supprim√©es"
            )
            
            if st.button("Appliquer la suppression de lignes"):
                # Calcul du pourcentage de valeurs manquantes par ligne
                missing_percentage = data.isnull().mean(axis=1) * 100
                
                # Filtrer les lignes avec moins de valeurs manquantes que le seuil
                filtered_data = data[missing_percentage <= threshold]
                
                # Afficher les r√©sultats
                removed_rows = len(data) - len(filtered_data)
                st.info(f"{removed_rows} lignes supprim√©es sur {len(data)} ({removed_rows/len(data)*100:.2f}%)")
                
                treated_data = filtered_data
                st.session_state.processed_data = treated_data
                
                # Montrer un aper√ßu
                st.write("Aper√ßu des donn√©es apr√®s suppression:")
                st.dataframe(clean_dataframe_for_display(treated_data).head())
                
                # Mettre √† jour les statistiques de valeurs manquantes
                new_missing = treated_data.isnull().sum().sum()
                st.write(f"Valeurs manquantes restantes: {new_missing} (sur {missing_total} initialement)")
        
        else:  # Supprimer les colonnes
            col_threshold = st.slider(
                "Seuil de suppression (% maximum de valeurs manquantes par colonne)",
                min_value=0,
                max_value=100,
                value=50,
                step=5,
                help="Les colonnes avec un pourcentage de valeurs manquantes sup√©rieur √† ce seuil seront supprim√©es"
            )
            
            if st.button("Appliquer la suppression de colonnes"):
                # Calculer le pourcentage de valeurs manquantes par colonne
                missing_percentage = data.isnull().mean() * 100
                
                # S√©lectionner les colonnes √† conserver
                columns_to_keep = missing_percentage[missing_percentage <= col_threshold].index.tolist()
                filtered_data = data[columns_to_keep]
                
                # Afficher les r√©sultats
                removed_cols = len(data.columns) - len(filtered_data.columns)
                st.info(f"{removed_cols} colonnes supprim√©es sur {len(data.columns)} ({removed_cols/len(data.columns)*100:.2f}%)")
                
                treated_data = filtered_data
                st.session_state.processed_data = treated_data
                
                # Montrer un aper√ßu
                st.write("Aper√ßu des donn√©es apr√®s suppression:")
                st.dataframe(clean_dataframe_for_display(treated_data).head())
                
                # Mettre √† jour les statistiques de valeurs manquantes
                new_missing = treated_data.isnull().sum().sum()
                st.write(f"Valeurs manquantes restantes: {new_missing} (sur {missing_total} initialement)")
    
    # Onglet 2: Imputation Simple
    with treatment_tabs[1]:
        st.write("### Imputation simple des valeurs manquantes")
        
        # S√©parer les colonnes num√©riques et cat√©gorielles
        numeric_cols = data.select_dtypes(include=['number']).columns.tolist()
        categorical_cols = data.select_dtypes(exclude=['number']).columns.tolist()
        
        # Obtenir les colonnes avec valeurs manquantes
        numeric_missing = [col for col in numeric_cols if col in missing_cols]
        categorical_missing = [col for col in categorical_cols if col in missing_cols]
        
        # M√©thodes d'imputation pour colonnes num√©riques
        if numeric_missing:
            st.write("#### Colonnes num√©riques avec valeurs manquantes:")
            st.write(", ".join(numeric_missing))
            
            numeric_method = st.selectbox(
                "M√©thode d'imputation pour variables num√©riques:",
                ["Moyenne", "M√©diane", "Constante"]
            )
            
            numeric_constant = None
            if numeric_method == "Constante":
                numeric_constant = st.number_input("Valeur constante pour l'imputation num√©rique:", value=0.0)
        
        # M√©thodes d'imputation pour colonnes cat√©gorielles
        if categorical_missing:
            st.write("#### Colonnes cat√©gorielles avec valeurs manquantes:")
            st.write(", ".join(categorical_missing))
            
            categorical_method = st.selectbox(
                "M√©thode d'imputation pour variables cat√©gorielles:",
                ["Mode (valeur la plus fr√©quente)", "Constante"]
            )
            
            categorical_constant = None
            if categorical_method == "Constante":
                categorical_constant = st.text_input("Valeur constante pour l'imputation cat√©gorielle:", value="Inconnu")
        
        if st.button("Appliquer l'imputation simple"):
            imputed_data = data.copy()
            
            # Imputer les colonnes num√©riques
            if numeric_missing:
                for col in numeric_missing:
                    if numeric_method == "Moyenne":
                        imputed_data[col] = imputed_data[col].fillna(imputed_data[col].mean())
                    elif numeric_method == "M√©diane":
                        imputed_data[col] = imputed_data[col].fillna(imputed_data[col].median())
                    else:  # Constante
                        imputed_data[col] = imputed_data[col].fillna(numeric_constant)
            
            # Imputer les colonnes cat√©gorielles
            if categorical_missing:
                for col in categorical_missing:
                    if categorical_method == "Mode (valeur la plus fr√©quente)":
                        imputed_data[col] = imputed_data[col].fillna(imputed_data[col].mode()[0])
                    else:  # Constante
                        imputed_data[col] = imputed_data[col].fillna(categorical_constant)
            
            treated_data = imputed_data
            st.session_state.processed_data = treated_data
            
            # Afficher les r√©sultats
            st.write("Aper√ßu des donn√©es apr√®s imputation:")
            st.dataframe(clean_dataframe_for_display(treated_data).head())
            
            # Mettre √† jour les statistiques de valeurs manquantes
            new_missing = treated_data.isnull().sum().sum()
            st.success(f"Valeurs manquantes combl√©es: {missing_total - new_missing} sur {missing_total}")
            st.write(f"Valeurs manquantes restantes: {new_missing}")
    
    # Onglet 3: Imputation Avanc√©e
    with treatment_tabs[2]:
        st.write("### M√©thodes d'imputation avanc√©es")
        
        advanced_method = st.selectbox(
            "M√©thode d'imputation avanc√©e:",
            ["KNN (k plus proches voisins)", "MICE (Imputation multiple par √©quations cha√Æn√©es)"]
        )
        
        # Ajout d'une option pour le mode rapide
        fast_mode = st.checkbox(
            "Mode rapide (recommand√© pour grands jeux de donn√©es)", 
            value=True,
            help="Limite le nombre de colonnes et d'√©chantillons pour acc√©l√©rer le traitement"
        )
        
        max_cols = None
        if fast_mode:
            st.info("‚ö° Le mode rapide est activ√©. L'imputation sera plus rapide mais potentiellement moins pr√©cise.")
            # Permettre √† l'utilisateur de d√©finir une limite de colonnes √† traiter
            max_cols = st.slider(
                "Nombre maximum de colonnes √† traiter",
                min_value=5,
                max_value=30,
                value=15,
                help="Limiter le nombre de colonnes pour acc√©l√©rer le traitement"
            )
        
        if advanced_method == "KNN (k plus proches voisins)":
            n_neighbors = st.slider(
                "Nombre de voisins (k)",
                min_value=1,
                max_value=20,
                value=5,
                step=1,
                help="Nombre de voisins √† consid√©rer pour l'imputation KNN"
            )
            
            if st.button("Appliquer l'imputation KNN"):
                # Utiliser le module missing_values_handler avec la m√©thode KNN
                from .missing_values_handler import MissingValuesHandler
                
                # Message d'information sur le traitement
                info_msg = st.info("Pr√©paration des donn√©es pour l'imputation KNN... Veuillez patienter.")
                
                # Si mode rapide est activ√©, s√©lectionner un sous-ensemble de colonnes
                if fast_mode and max_cols and len(data.columns) > max_cols:
                    # Prioriser les colonnes avec valeurs manquantes
                    missing_counts = data.isnull().sum()
                    cols_to_process = list(missing_counts[missing_counts > 0].index)
                    
                    # Ajouter des colonnes sans valeurs manquantes jusqu'√† atteindre max_cols
                    other_cols = [c for c in data.columns if c not in cols_to_process]
                    import random
                    random.shuffle(other_cols)
                    cols_to_process.extend(other_cols[:max(0, max_cols - len(cols_to_process))])
                    
                    # Utiliser seulement ce sous-ensemble
                    subset_data = data[cols_to_process].copy()
                    st.write(f"Traitement limit√© √† {len(cols_to_process)} colonnes sur {len(data.columns)} pour des raisons de performance.")
                    handler = MissingValuesHandler(subset_data)
                else:
                    handler = MissingValuesHandler(data)
                
                # Mise √† jour du message
                info_msg.info("Application de l'imputation KNN... Cette op√©ration peut prendre du temps.")
                
                # Cr√©er une barre de progression
                progress_bar = st.progress(0)
                
                # Fonction pour mettre √† jour la progression
                def update_progress(progress):
                    progress_bar.progress(int(progress * 100))
                
                # Appliquer l'imputation KNN avec callback de progression
                try:
                    advanced_data = handler.apply_imputation('knn_imputation', n_neighbors=n_neighbors, progress_callback=update_progress)
                    
                    # Si on a utilis√© un sous-ensemble, r√©int√©grer les colonnes dans le jeu de donn√©es original
                    if fast_mode and max_cols and len(data.columns) > max_cols:
                        # Copier les donn√©es originales et mettre √† jour seulement les colonnes trait√©es
                        full_data = data.copy()
                        for col in cols_to_process:
                            # V√©rifier si la colonne existe encore dans les donn√©es trait√©es 
                            # (elle pourrait avoir √©t√© transform√©e par one-hot encoding)
                            if col in advanced_data.columns:
                                full_data[col] = advanced_data[col]
                            else:
                                st.info(f"La colonne {col} a √©t√© transform√©e ou supprim√©e pendant le traitement.")
                                # Chercher des colonnes d√©riv√©es (apr√®s one-hot encoding par exemple)
                                derived_cols = [c for c in advanced_data.columns if c.startswith(f"{col}_")]
                                if derived_cols:
                                    st.info(f"Colonnes d√©riv√©es trouv√©es: {', '.join(derived_cols)}")
                                    # Ajouter ces colonnes au DataFrame complet
                                    for derived_col in derived_cols:
                                        full_data[derived_col] = advanced_data[derived_col]
                        advanced_data = full_data
                    
                    # Finaliser
                    progress_bar.progress(100)
                    info_msg.success("Imputation KNN termin√©e avec succ√®s!")
                    
                    treated_data = advanced_data
                    st.session_state.processed_data = treated_data
                    
                    # Afficher les r√©sultats
                    st.write("Aper√ßu des donn√©es apr√®s imputation KNN:")
                    st.dataframe(clean_dataframe_for_display(treated_data).head())
                    
                    # V√©rifier les valeurs manquantes restantes
                    missing_total = data.isnull().sum().sum()
                    new_missing = treated_data.isnull().sum().sum()
                    st.success(f"Valeurs manquantes combl√©es: {missing_total - new_missing} sur {missing_total}")
                    st.write(f"Valeurs manquantes restantes: {new_missing}")
                except Exception as e:
                    info_msg.error(f"Erreur lors de l'imputation KNN: {str(e)}")
                    st.exception(e)
        
        else:  # MICE
            max_iter = st.slider(
                "Nombre maximum d'it√©rations",
                min_value=1,
                max_value=50,
                value=10,
                step=1,
                help="Nombre maximum d'it√©rations pour l'imputation it√©rative"
            )
            
            if st.button("Appliquer l'imputation MICE"):
                # Utiliser le module missing_values_handler avec la m√©thode MICE
                from .missing_values_handler import MissingValuesHandler
                
                # Message d'information sur le traitement
                info_msg = st.info("Pr√©paration des donn√©es pour l'imputation MICE... Veuillez patienter.")
                
                # Si mode rapide est activ√©, s√©lectionner un sous-ensemble de colonnes
                if fast_mode and max_cols and len(data.columns) > max_cols:
                    # Prioriser les colonnes avec valeurs manquantes
                    missing_counts = data.isnull().sum()
                    cols_to_process = list(missing_counts[missing_counts > 0].index)
                    
                    # Ajouter des colonnes sans valeurs manquantes jusqu'√† atteindre max_cols
                    other_cols = [c for c in data.columns if c not in cols_to_process]
                    import random
                    random.shuffle(other_cols)
                    cols_to_process.extend(other_cols[:max(0, max_cols - len(cols_to_process))])
                    
                    # Utiliser seulement ce sous-ensemble
                    subset_data = data[cols_to_process].copy()
                    st.write(f"Traitement limit√© √† {len(cols_to_process)} colonnes sur {len(data.columns)} pour des raisons de performance.")
                    handler = MissingValuesHandler(subset_data)
                else:
                    handler = MissingValuesHandler(data)
                
                # Mise √† jour du message
                info_msg.info("Application de l'imputation MICE... Cette op√©ration peut prendre du temps.")
                
                # Cr√©er une barre de progression
                progress_bar = st.progress(0)
                
                # Fonction pour mettre √† jour la progression
                def update_progress(progress):
                    progress_bar.progress(int(progress * 100))
                
                # Appliquer l'imputation MICE avec callback de progression
                try:
                    advanced_data = handler.apply_imputation('iterative_imputation', max_iter=max_iter, progress_callback=update_progress)
                    
                    # Si on a utilis√© un sous-ensemble, r√©int√©grer les colonnes dans le jeu de donn√©es original
                    if fast_mode and max_cols and len(data.columns) > max_cols:
                        # Copier les donn√©es originales et mettre √† jour seulement les colonnes trait√©es
                        full_data = data.copy()
                        for col in cols_to_process:
                            # V√©rifier si la colonne existe encore dans les donn√©es trait√©es 
                            # (elle pourrait avoir √©t√© transform√©e par one-hot encoding)
                            if col in advanced_data.columns:
                                full_data[col] = advanced_data[col]
                            else:
                                st.info(f"La colonne {col} a √©t√© transform√©e ou supprim√©e pendant le traitement.")
                                # Chercher des colonnes d√©riv√©es (apr√®s one-hot encoding par exemple)
                                derived_cols = [c for c in advanced_data.columns if c.startswith(f"{col}_")]
                                if derived_cols:
                                    st.info(f"Colonnes d√©riv√©es trouv√©es: {', '.join(derived_cols)}")
                                    # Ajouter ces colonnes au DataFrame complet
                                    for derived_col in derived_cols:
                                        full_data[derived_col] = advanced_data[derived_col]
                        advanced_data = full_data
                    
                    # Finaliser
                    progress_bar.progress(100)
                    info_msg.success("Imputation MICE termin√©e avec succ√®s!")
                    
                    treated_data = advanced_data
                    st.session_state.processed_data = treated_data
                    
                    # Afficher les r√©sultats
                    st.write("Aper√ßu des donn√©es apr√®s imputation MICE:")
                    st.dataframe(clean_dataframe_for_display(treated_data).head())
                    
                    # V√©rifier les valeurs manquantes restantes
                    missing_total = data.isnull().sum().sum()
                    new_missing = treated_data.isnull().sum().sum()
                    st.success(f"Valeurs manquantes combl√©es: {missing_total - new_missing} sur {missing_total}")
                    st.write(f"Valeurs manquantes restantes: {new_missing}")
                except Exception as e:
                    info_msg.error(f"Erreur lors de l'imputation MICE: {str(e)}")
                    st.exception(e)
    
    # Onglet 4: R√©sultats
    with treatment_tabs[3]:
        st.write("### T√©l√©chargement et Finalisation")
        
        if hasattr(st.session_state, 'processed_data'):
            treated_data = st.session_state.processed_data
            
            # Statistiques apr√®s traitement
            st.write("#### Statistiques apr√®s traitement")
            
            # V√©rifier les valeurs manquantes restantes
            new_missing = treated_data.isnull().sum().sum()
            new_missing_by_col = treated_data.isnull().sum()
            new_missing_cols = new_missing_by_col[new_missing_by_col > 0].index.tolist()
            
            # Cr√©er un r√©capitulatif
            st.write(f"**Valeurs manquantes combl√©es:** {missing_total - new_missing} sur {missing_total}")
            st.write(f"**Taux de compl√©tion:** {((missing_total - new_missing) / missing_total * 100):.2f}%")
            
            if new_missing > 0:
                st.warning(f"**Valeurs manquantes restantes:** {new_missing}")
                
                # Afficher les colonnes avec valeurs manquantes restantes
                st.write("Colonnes avec valeurs manquantes restantes:")
                st.dataframe(pd.DataFrame({
                    'Colonne': new_missing_cols,
                    'Valeurs manquantes': [new_missing_by_col[col] for col in new_missing_cols],
                    'Pourcentage': [f"{new_missing_by_col[col] / len(treated_data) * 100:.2f}%" for col in new_missing_cols]
                }))
            else:
                st.success("**Toutes les valeurs manquantes ont √©t√© trait√©es !**")
            
            # T√©l√©chargement des donn√©es trait√©es
            st.write("#### T√©l√©charger les donn√©es trait√©es")
            
            # Nettoyer et sauvegarder les donn√©es trait√©es en CSV
            clean_treated_data = clean_dataframe_for_display(treated_data)
            csv = clean_treated_data.to_csv(index=False).encode('utf-8')
            b64 = base64.b64encode(csv).decode()
            href = f'<a href="data:file/csv;base64,{b64}" download="donnees_traitees.csv">T√©l√©charger les donn√©es trait√©es (CSV)</a>'
            st.markdown(href, unsafe_allow_html=True)
            
            # Bouton pour finaliser et retourner au traitement
            if st.button("Finaliser et retourner au traitement", type="primary"):
                if 'return_to' in st.session_state:
                    # Effacer le flag de page des valeurs manquantes
                    del st.session_state.show_missing_values_page
                    # Conserver les donn√©es trait√©es et le flag de retour
                    # Ils seront utilis√©s dans la page principale
                    st.rerun()
        else:
            st.info("Veuillez d'abord appliquer une m√©thode de traitement des valeurs manquantes.")

def clean_dataframe_for_display(df):
    """
    Nettoie un DataFrame pour s'assurer qu'il peut √™tre affich√© correctement dans Streamlit.
    
    Args:
        df: Le DataFrame √† nettoyer
        
    Returns:
        DataFrame nettoy√© avec des types compatibles
    """
    # Cr√©er une copie pour √©viter de modifier l'original
    clean_df = df.copy()
    
    # Parcourir toutes les colonnes
    for col in clean_df.columns:
        # Si la colonne est de type objet, convertir en string
        if clean_df[col].dtype == 'object':
            # Essayer de convertir les objets en string
            try:
                clean_df[col] = clean_df[col].apply(lambda x: str(x) if x is not None else None)
            except Exception:
                # En cas d'√©chec, remplacer par des cha√Ænes vides
                clean_df[col] = clean_df[col].apply(lambda x: "" if pd.isna(x) else str(x))
        
        # Pour les bool√©ens, convertir en entiers (0/1)
        elif clean_df[col].dtype == 'bool':
            clean_df[col] = clean_df[col].astype(int)
    
    return clean_df

def render_ai_methods_tab():
    """Rendre l'onglet des m√©thodes d'IA dans Streamlit"""
    # V√©rifier si nous devons afficher la page de gestion des valeurs manquantes
    if hasattr(st.session_state, 'show_missing_values_page') and st.session_state.show_missing_values_page:
        show_missing_values_interface()
        return
    
    st.header("G√©n√©ration de Donn√©es avec l'Intelligence Artificielle")
    
    subtab1, subtab2 = st.tabs(["IA pour Donn√©es Synth√©tiques", "IA pour Donn√©es Artificielles"])
    
    with subtab1:
        st.subheader("G√©n√©ration de Donn√©es Synth√©tiques avec l'IA")
        st.write("""
        Cette section vous permet d'utiliser des techniques avanc√©es d'intelligence artificielle 
        pour g√©n√©rer des donn√©es synth√©tiques √† partir de donn√©es r√©elles.
        """)
        
        # Options: GAN, VAE ou m√©thodes simples
        ai_method = st.radio(
            "S√©lectionnez la m√©thode d'IA:",
            [
                "GAN (Generative Adversarial Network)",
                "VAE (Variational Autoencoder)",
                "M√©thodes statistiques simples (GMM, PCA)"
            ],
            index=0
        )
        
        # Avertissement PyTorch
        if not TORCH_AVAILABLE and (ai_method.startswith("GAN") or ai_method.startswith("VAE")):
            st.warning("""
            PyTorch n'est pas install√©. Pour utiliser GAN ou VAE, installez PyTorch:
            
            ```bash
            pip install torch
            ```
            
            Puis red√©marrez l'application. Vous pouvez toujours utiliser les m√©thodes statistiques simples.
            """)
        elif ai_method.startswith("GAN") and not GAN_AVAILABLE:
            st.warning("""
            Le module tabular_gan.py n'est pas disponible. 
            Assurez-vous qu'il est pr√©sent dans le r√©pertoire du projet.
            """)
        elif ai_method.startswith("VAE") and not VAE_AVAILABLE:
            st.warning("""
            Le module tabular_vae.py n'est pas disponible. 
            Assurez-vous qu'il est pr√©sent dans le r√©pertoire du projet.
            """)
        
        # Information sur l'acc√©l√©ration GPU
        if TORCH_AVAILABLE and CUDA_AVAILABLE and (ai_method.startswith("GAN") or ai_method.startswith("VAE")):
            st.success("L'acc√©l√©ration GPU (CUDA) est disponible et sera utilis√©e pour l'entra√Ænement.")
        elif TORCH_AVAILABLE and (ai_method.startswith("GAN") or ai_method.startswith("VAE")):
            st.info("PyTorch est disponible mais l'acc√©l√©ration GPU (CUDA) n'est pas d√©tect√©e. L'entra√Ænement utilisera le CPU.")
        
        # Charger des donn√©es r√©elles
        uploaded_file = st.file_uploader("Charger un fichier CSV contenant des donn√©es r√©elles", 
                                        type="csv", key="ai_synth_upload")
        
        if uploaded_file is not None:
            # Charger les donn√©es
            try:
                # Utiliser la fonction s√©curis√©e pour charger le CSV
                with st.spinner("Chargement et analyse du fichier CSV..."):
                    real_data = load_csv_safely(uploaded_file)
                
                if real_data is None:
                    st.error("Impossible de charger le fichier CSV. Veuillez v√©rifier le format.")
                else:
                    # V√©rifier les valeurs manquantes
                    missing_values = real_data.isnull().sum().sum()
                    if missing_values > 0:
                        st.warning(f"‚ö†Ô∏è {missing_values} valeurs manquantes d√©tect√©es dans le jeu de donn√©es.")
                        if st.button("G√©rer les valeurs manquantes"):
                            # Cr√©er une page d√©di√©e pour la gestion des valeurs manquantes
                            st.session_state.show_missing_values_page = True
                            st.session_state.original_data = real_data.copy()
                            # Mettre un flag pour indiquer o√π revenir apr√®s traitement
                            st.session_state.return_to = "ai_methods_tab"
                            st.rerun()
                    
                    # V√©rifier si nous revenons du traitement des valeurs manquantes
                    if hasattr(st.session_state, 'processed_data') and st.session_state.get('return_to') == "ai_methods_tab":
                        # R√©cup√©rer les donn√©es trait√©es
                        real_data = st.session_state.processed_data
                        # Nettoyer les variables de session
                        st.success("üéâ Les valeurs manquantes ont √©t√© trait√©es avec succ√®s !")
                        del st.session_state.processed_data
                        del st.session_state.return_to
                    
                    # Afficher un aper√ßu des donn√©es r√©elles
                    st.subheader("Aper√ßu des Donn√©es R√©elles")
                    st.write(real_data.head())
                    
                    # Analyse des donn√©es et d√©tection automatique des types
                    analysis = DataProcessor.analyze_data(real_data)
                    
                    with st.expander("Analyse des Donn√©es et D√©tection des Types", expanded=True):
                        # Afficher les statistiques de base
                        st.write(f"Total des lignes: {analysis['total_rows']}")
                        st.write(f"Total des colonnes: {len(analysis['columns'])}")
                        
                        # Afficher les types d√©tect√©s
                        st.subheader("Types de Colonnes D√©tect√©s Automatiquement")
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.write("**Colonnes num√©riques:**")
                            for col in analysis["column_types"]["numeric"]:
                                is_int = col in analysis["column_types"]["integer"]
                                is_binary = col in analysis["column_types"]["binary"]
                                type_info = ""
                                if is_int: 
                                    type_info += " (entier)"
                                if is_binary:
                                    type_info += " (binaire 0/1)"
                                st.write(f"- {col}{type_info}")
                        
                        with col2:
                            st.write("**Colonnes cat√©gorielles:**")
                            for col in analysis["column_types"]["categorical"]:
                                is_binary = col in analysis["column_types"]["binary"]
                                type_info = " (binaire 0/1)" if is_binary else ""
                                st.write(f"- {col}{type_info}")
                        
                        # Permettre √† l'utilisateur de modifier les types d√©tect√©s
                        st.subheader("Modifier les Types de Colonnes (si n√©cessaire)")
                        
                        # Utiliser des multi-selects pour choisir les types
                        all_columns = real_data.columns.tolist()
                        
                        categorical_override = st.multiselect(
                            "Colonnes √† traiter comme cat√©gorielles:",
                            all_columns,
                            default=analysis["column_types"]["categorical"],
                            help="S√©lectionnez toutes les colonnes qui devraient √™tre trait√©es comme cat√©gorielles, m√™me si elles contiennent des nombres (ex: codes, ID, variables binaires 0/1)"
                        )
                        
                        if analysis['missing_values']:
                            st.warning("Valeurs manquantes d√©tect√©es dans ces colonnes:")
                            for col, count in analysis['missing_values'].items():
                                st.write(f"- {col}: {count} valeurs manquantes")
                    
                    try:
                        # Pr√©traiter les donn√©es avec les types sp√©cifi√©s par l'utilisateur
                        with st.spinner("Pr√©traitement des donn√©es..."):
                            preprocessed_data, metadata = DataProcessor.preprocess_data(
                                real_data, 
                                categorical_cols_override=categorical_override
                            )
                        
                        # Param√®tres d'entra√Ænement
                        st.subheader("Param√®tres d'Entra√Ænement")
                        
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            if ai_method.startswith("M√©thodes statistiques"):
                                method_type = st.selectbox(
                                    "M√©thode statistique",
                                    ["gmm", "pca"],
                                    index=0,
                                    format_func=lambda x: "M√©lange de Gaussiennes (GMM)" if x == "gmm" else "Analyse en Composantes Principales (PCA)"
                                )
                                n_components = st.slider(
                                    "Nombre de composantes",
                                    min_value=1,
                                    max_value=20,
                                    value=5,
                                    step=1,
                                    help="Nombre de composantes/clusters pour la m√©thode statistique"
                                )
                            else:
                                latent_dim = st.slider(
                                    "Dimension de l'espace latent",
                                    min_value=2,
                                    max_value=50,
                                    value=16,
                                    step=1,
                                    help="Dimension de l'espace latent pour le mod√®le g√©n√©rateur"
                                )
                                
                                epochs = st.slider(
                                    "Nombre d'√©poques",
                                    min_value=10,
                                    max_value=1000,
                                    value=100,
                                    step=10,
                                    help="Nombre d'it√©rations compl√®tes sur les donn√©es d'entra√Ænement"
                                )
                        
                        with col2:
                            if not ai_method.startswith("M√©thodes statistiques"):
                                batch_size = st.slider(
                                    "Taille du batch",
                                    min_value=8,
                                    max_value=128,
                                    value=32,
                                    step=8,
                                    help="Nombre d'exemples trait√©s en une seule fois"
                                )
                            
                            n_samples = st.slider(
                                "Nombre d'√©chantillons √† g√©n√©rer",
                                min_value=100,
                                max_value=5000,
                                value=len(real_data),
                                step=100,
                                help="Nombre d'√©chantillons synth√©tiques √† g√©n√©rer"
                            )
                        
                        # Param√®tres avanc√©s
                        with st.expander("Param√®tres Avanc√©s"):
                            if ai_method.startswith("GAN"):
                                learning_rate = st.number_input(
                                    "Taux d'apprentissage",
                                    min_value=0.0001,
                                    max_value=0.01,
                                    value=0.0002,
                                    format="%.5f",
                                    help="Taille des pas pour les mises √† jour du gradient"
                                )
                                
                                early_stopping = st.slider(
                                    "Patience pour l'arr√™t anticip√©",
                                    min_value=10,
                                    max_value=100,
                                    value=30,
                                    step=5,
                                    help="Nombre d'√©poques sans am√©lioration avant l'arr√™t"
                                )
                            elif ai_method.startswith("VAE"):
                                beta_value = st.slider(
                                    "Valeur beta",
                                    min_value=0.1,
                                    max_value=5.0,
                                    value=1.0,
                                    step=0.1,
                                    help="Poids pour le terme de divergence KL (des valeurs plus √©lev√©es imposent un espace latent plus d√©senchev√™tr√©)"
                                )
                                
                                learning_rate = st.number_input(
                                    "Taux d'apprentissage",
                                    min_value=0.00001,
                                    max_value=0.01,
                                    value=0.0001,
                                    format="%.5f",
                                    help="Taille des pas pour les mises √† jour du gradient"
                                )
                                
                                early_stopping = st.slider(
                                    "Patience pour l'arr√™t anticip√©",
                                    min_value=5,
                                    max_value=50,
                                    value=10,
                                    step=1,
                                    help="Nombre d'√©poques sans am√©lioration avant l'arr√™t"
                                )
                        
                        # Persistance du mod√®le
                        save_model_option = st.checkbox(
                            "Sauvegarder le mod√®le entra√Æn√©", 
                            value=False,
                            help="Sauvegarder le mod√®le entra√Æn√© pour une utilisation future"
                        )
                        
                        if save_model_option:
                            model_path = st.text_input(
                                "Chemin de sauvegarde du mod√®le", 
                                value=f"./models/{ai_method.split(' ')[0].lower()}_model",
                                help="Chemin o√π le mod√®le sera sauvegard√©"
                            )
                        
                        # Avertissement sur le temps d'entra√Ænement
                        st.markdown("""
                        <div style="padding: 1rem; border-radius: 0.5rem; background-color: #fff8e1; border: 1px solid #ffc107;">
                        <b>‚ö†Ô∏è Note:</b> L'entra√Ænement peut prendre plusieurs minutes selon la taille des donn√©es
                        et les param√®tres choisis. Un arr√™t anticip√© sera effectu√© si aucune am√©lioration n'est observ√©e
                        apr√®s plusieurs √©poques.
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # Bouton pour lancer l'entra√Ænement
                        if st.button("Entra√Æner le mod√®le et g√©n√©rer des donn√©es", key="train_ai_model"):
                            try:
                                # Cr√©er et entra√Æner le mod√®le
                                if ai_method.startswith("GAN") and GAN_AVAILABLE:
                                    st.info("Entra√Ænement du GAN en cours...")
                                    
                                    # Configuration des param√®tres pour GAN
                                    gan_params = {
                                        'latent_dim': latent_dim,
                                        'epochs': epochs,
                                        'batch_size': batch_size,
                                        'n_samples': n_samples,
                                        'learning_rate': learning_rate,
                                        'early_stopping': early_stopping
                                    }
                                    
                                    # D√©marrer un indicateur de progression
                                    progress_bar = st.progress(0)
                                    
                                    # Entra√Æner le mod√®le GAN
                                    model, synthetic_data = train_gan_model(preprocessed_data, metadata, gan_params)
                                    
                                    # Mise √† jour de l'indicateur de progression
                                    progress_bar.progress(100)
                                    
                                    # Sauvegarder le mod√®le si demand√©
                                    if save_model_option:
                                        save_model(model, model_path, model_type='gan')
                                        st.success(f"Mod√®le GAN sauvegard√© avec succ√®s √† {model_path}")
                                    
                                elif ai_method.startswith("VAE") and VAE_AVAILABLE:
                                    st.info("Entra√Ænement du VAE en cours...")
                                    
                                    # Configuration des param√®tres pour VAE
                                    vae_params = {
                                        'latent_dim': latent_dim,
                                        'epochs': epochs,
                                        'batch_size': batch_size,
                                        'n_samples': n_samples,
                                        'learning_rate': learning_rate,
                                        'beta': beta_value,
                                        'early_stopping': early_stopping
                                    }
                                    
                                    # D√©marrer un indicateur de progression
                                    progress_bar = st.progress(0)
                                    
                                    # Entra√Æner le mod√®le VAE
                                    model, synthetic_data = train_vae_model(preprocessed_data, metadata, vae_params)
                                    
                                    # Mise √† jour de l'indicateur de progression
                                    progress_bar.progress(100)
                                    
                                    # Sauvegarder le mod√®le si demand√©
                                    if save_model_option:
                                        save_model(model, model_path, model_type='vae')
                                        st.success(f"Mod√®le VAE sauvegard√© avec succ√®s √† {model_path}")
                                    
                                else:  # M√©thodes statistiques simples
                                    st.info(f"Utilisation de la m√©thode statistique {method_type.upper()}...")
                                    
                                    # G√©n√©rer des donn√©es avec les m√©thodes statistiques
                                    synthetic_data = generate_with_statistical_methods(
                                        preprocessed_data, 
                                        metadata, 
                                        method_type, 
                                        n_components, 
                                        n_samples
                                    )
                                
                                # Convertir les donn√©es synth√©tiques au format original
                                synthetic_df = DataProcessor.inverse_transform(synthetic_data, metadata)
                                
                                # Afficher les donn√©es g√©n√©r√©es
                                st.subheader("Donn√©es Synth√©tiques G√©n√©r√©es")
                                
                                # Nettoyer le DataFrame pour l'affichage
                                clean_synthetic_df = clean_dataframe_for_display(synthetic_df)
                                
                                # Afficher les donn√©es g√©n√©r√©es
                                st.write("Aper√ßu des donn√©es synth√©tiques:")
                                st.write(clean_synthetic_df.head())
                                
                                # Afficher les types de donn√©es
                                st.write("Types des colonnes g√©n√©r√©es:")
                                st.write(clean_synthetic_df.dtypes)
                                
                                # Option de t√©l√©chargement
                                st.download_button(
                                    label="T√©l√©charger les Donn√©es Synth√©tiques (CSV)",
                                    data=clean_synthetic_df.to_csv(index=False).encode('utf-8'),
                                    file_name="donnees_synthetiques.csv",
                                    mime="text/csv"
                                )
                                
                                # Visualisations comparatives
                                st.subheader("Visualisations Comparatives")
                                
                                for col in metadata.categorical_cols:
                                    if clean_synthetic_df[col].nunique() < 15:  # Seulement pour les colonnes avec un nombre raisonnable de cat√©gories
                                        fig = visualize_categorical_comparison(real_data, clean_synthetic_df, col)
                                        st.pyplot(fig)

                                # Pour les colonnes num√©riques
                                for col in metadata.numeric_cols:
                                    fig = visualize_numeric_comparison(real_data, clean_synthetic_df, col)
                                    st.pyplot(fig)
                                
                                # Statistiques descriptives
                                st.subheader("Statistiques Descriptives")
                                
                                if metadata.numeric_cols:
                                    col1, col2 = st.columns(2)
                                    
                                    with col1:
                                        st.write("**Donn√©es r√©elles:**")
                                        st.write(real_data[metadata.numeric_cols].describe())
                                    
                                    with col2:
                                        st.write("**Donn√©es synth√©tiques:**")
                                        st.write(clean_synthetic_df[metadata.numeric_cols].describe())
                                
                            except Exception as e:
                                st.error(f"Une erreur s'est produite: {str(e)}")
                                import traceback
                                st.exception(traceback.format_exc())
                    except Exception as e:
                        st.error(f"Erreur lors du pr√©traitement: {str(e)}")
                        import traceback
                        st.exception(traceback.format_exc())
            except Exception as e:
                st.error(f"Erreur lors du chargement du fichier CSV: {str(e)}")
                import traceback
                st.exception(traceback.format_exc())
    
    with subtab2:
        # Code pour l'onglet des donn√©es artificielles (LLM)
        st.subheader("G√©n√©ration de Donn√©es Artificielles avec LLM")
        render_llm_tab()